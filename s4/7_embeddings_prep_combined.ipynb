{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bfecd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from hmpai.training import split_participants, split_participants_custom\n",
    "from hmpai.pytorch.training import train_and_test\n",
    "from hmpai.pytorch.utilities import DEVICE, set_global_seed, load_model\n",
    "from hmpai.pytorch.generators import MultiXArrayProbaDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from hmpai.pytorch.normalization import *\n",
    "from torchvision.transforms import Compose\n",
    "from hmpai.pytorch.transforms import *\n",
    "from hmpai.pytorch.mamba import *\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8df765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in models and data (val set)\n",
    "\n",
    "# Predict on val set, saving embeddings and predicted probas\n",
    "\n",
    "# Maybe as xr?\n",
    "# Include dataset as variable (prp/task1, prp/task2, sat_weindel, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6c681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)\n",
    "\n",
    "data_paths = [DATA_PATH / \"prp/stage_data_250hz_t1.nc\", DATA_PATH / \"prp/stage_data_250hz_t2.nc\"]\n",
    "# 80/20 train/val (no test)\n",
    "splits = split_participants_custom(data_paths, 0)\n",
    "# Labels per dataset (same order as data_paths)\n",
    "data_labels = [[\"negative\", \"t1_1\", \"t1_2\", \"t1_3\"], [\"negative\", \"t2_1\", \"t2_2\", \"t2_3\"]]\n",
    "# Labels combined\n",
    "labels = [\"negative\", \"t1_1\", \"t1_2\", \"t1_3\", \"t2_1\", \"t2_2\", \"t2_3\"]\n",
    "info_to_keep = [\"participant\", \"condition\", \"trial_index\", \"task\"]\n",
    "# subset_cond = ('condition', 'equal', 'long')\n",
    "subset_cond = None\n",
    "add_negative = True\n",
    "skip_samples = 62 # 62\n",
    "cut_samples = 63 # 63\n",
    "add_pe = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6792d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, loader, labels, participants, window_size=6):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    n_labels = len(labels) - 1  # Exclude 'negative' label\n",
    "    emb_dim = model.mamba_dim\n",
    "    epochs_per_participant = 1316\n",
    "\n",
    "    # Create empty dataset\n",
    "    final_ds = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"embeddings\": (\n",
    "                (\"participant\", \"epochs\", \"labels\", \"emb_dim\"),\n",
    "                np.full((len(participants), epochs_per_participant, n_labels, emb_dim), np.nan, dtype=np.float32)\n",
    "            ),\n",
    "            \"condition\": ((\"participant\", \"epochs\"), np.full((len(participants), epochs_per_participant), \"\", dtype=object)),\n",
    "            \"confidence\": ((\"participant\", \"epochs\", \"labels\"), np.full((len(participants), epochs_per_participant, n_labels), np.nan, dtype=np.float32)),\n",
    "        },\n",
    "        coords={\n",
    "            \"participant\": participants,\n",
    "            \"epochs\": np.arange(epochs_per_participant),\n",
    "            \"labels\": labels[1:],\n",
    "            \"emb_dim\": np.arange(emb_dim),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, total=len(loader)):\n",
    "            info = batch[2][0]\n",
    "            pred, emb = model(batch[0].to(DEVICE), return_embeddings=True, task=info[\"task\"])\n",
    "            pred = torch.nn.Softmax(dim=2)(pred).to(\"cpu\")\n",
    "            # pred: (batch_size, time, n_classes)\n",
    "            # emb: (batch_size, time, model_dim)\n",
    "            # info: dict of key: list\n",
    "            peaks = pred[..., 1:].argmax(dim=1)\n",
    "\n",
    "            # Get embeddings for each label's peak (shape: batch × labels × emb_dim)\n",
    "            B, T, D = emb.shape\n",
    "            emb_cpu = emb.cpu()\n",
    "            # now build a (B, n_labels, emb_dim) tensor\n",
    "            window_emb = torch.zeros((B, n_labels, D),\n",
    "                                     dtype=emb_cpu.dtype)\n",
    "            window_conf = torch.zeros((B, n_labels), dtype=pred.dtype)\n",
    "            pre = post = window_size\n",
    "\n",
    "            for i in range(B):\n",
    "                for lab in range(n_labels):\n",
    "                    p = peaks[i, lab].item()\n",
    "                    start = max(0, p - pre)\n",
    "                    stop  = min(T, p + post + 1)\n",
    "                    # average over that little window\n",
    "                    window_emb[i, lab, :] = emb_cpu[i, start:stop, :].mean(dim=0)\n",
    "                    window_conf[i, lab] = pred[i, start:stop, lab + 1].mean()\n",
    "\n",
    "            # bring back to cpu for numpy/xarray\n",
    "            peak_emb = window_emb.numpy()  \n",
    "            \n",
    "            for i, p in enumerate(info[\"participant\"]):\n",
    "                idx = participants.index(p)\n",
    "                epoch_idx = info[\"trial_index\"][i].int()\n",
    "                \n",
    "                if info[\"task\"][i] == \"prp1/t1\":\n",
    "                    final_ds[\"embeddings\"][idx, epoch_idx, :3, :] = peak_emb[i, :3]\n",
    "                    final_ds[\"confidence\"][idx, epoch_idx, :3] = window_conf[i, :3]\n",
    "                elif info[\"task\"][i] == \"prp1/t2\":\n",
    "                    final_ds[\"embeddings\"][idx, epoch_idx, 3:, :] = peak_emb[i, 3:]\n",
    "                    final_ds[\"confidence\"][idx, epoch_idx, 3:] = window_conf[i, 3:]\n",
    "                final_ds[\"condition\"][idx, epoch_idx] = info[\"condition\"][i]\n",
    "    return final_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb36e7",
   "metadata": {},
   "source": [
    "### prp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "363978ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fn = norm_mad_zscore\n",
    "train_data = MultiXArrayProbaDataset(\n",
    "    data_paths,\n",
    "    participants_to_keep=splits[0],\n",
    "    normalization_fn=norm_fn,\n",
    "    labels=labels,\n",
    "    data_labels=data_labels,\n",
    "    info_to_keep=info_to_keep,\n",
    "    subset_cond=subset_cond,\n",
    "    add_negative=add_negative,\n",
    "    # transform=Compose([StartJitterTransform(62, 1.0), EndJitterTransform(63, 1.0)]),\n",
    "    skip_samples=skip_samples,\n",
    "    cut_samples=cut_samples,\n",
    "    add_pe=add_pe,\n",
    ")\n",
    "# norm_vars = get_norm_vars_from_global_statistics(train_data.statistics, norm_fn)\n",
    "# class_weights = train_data.statistics[\"class_weights\"]\n",
    "# val_data = MultiXArrayProbaDataset(\n",
    "#     data_paths,\n",
    "#     participants_to_keep=splits[1],\n",
    "#     normalization_fn=norm_fn,\n",
    "#     norm_vars=norm_vars,\n",
    "#     labels=labels,\n",
    "#     data_labels=data_labels,\n",
    "#     info_to_keep=info_to_keep,\n",
    "#     subset_cond=subset_cond,\n",
    "#     add_negative=add_negative,\n",
    "#     skip_samples=skip_samples,\n",
    "#     cut_samples=cut_samples,\n",
    "#     add_pe=add_pe,\n",
    "# )\n",
    "# del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103b5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=32, shuffle=True, num_workers=12, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05106d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_path = Path(\"../models/cmb_shared.pt\")\n",
    "checkpoint = load_model(chk_path)\n",
    "config = {\n",
    "    \"n_channels\": 64,\n",
    "    \"n_classes\": len(labels),\n",
    "    \"n_mamba_layers\": 5,\n",
    "    \"use_pointconv_fe\": True,\n",
    "    \"spatial_feature_dim\": 128,\n",
    "    \"use_conv\": True,\n",
    "    \"conv_kernel_sizes\": [3, 9],\n",
    "    \"conv_in_channels\": [128, 128],\n",
    "    \"conv_out_channels\": [256, 256],\n",
    "    \"conv_concat\": True,\n",
    "    \"use_pos_enc\": add_pe,\n",
    "}\n",
    "\n",
    "model = build_mamba(config)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ba4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33091351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440658dcc662448ca27fe6275789bd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1_embs_ds = get_embeddings(model, train_loader, labels, splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f7c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_embs_ds.to_netcdf(\"files/cmb_embeddings.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
