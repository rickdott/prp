{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_participants\n",
    "from hmpai.pytorch.utilities import set_global_seed\n",
    "from hmpai.pytorch.generators import MultiXArrayProbaDataset\n",
    "from hmpai.pytorch.normalization import *\n",
    "from hmpai.pytorch.transforms import *\n",
    "from hmpai.pytorch.mamba import *\n",
    "from hmpai.pytorch.training import train_and_test\n",
    "\n",
    "from mne.io import read_info\n",
    "import os\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in t1, t2 and cmb\n",
    "t1_path = DATA_PATH / \"prp/stage_data_250hz_t1.nc\"\n",
    "t2_path = DATA_PATH / \"prp/stage_data_250hz_t2.nc\"\n",
    "cmb_path = DATA_PATH / \"prp/Data_trial_250Hz.nc\"\n",
    "\n",
    "t1 = xr.open_dataset(t1_path)\n",
    "t2 = xr.open_dataset(t2_path)\n",
    "cmb = xr.open_dataset(cmb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1315, 5, 500)\n",
      "(21, 1308, 3, 499)\n"
     ]
    }
   ],
   "source": [
    "# Goal: Create new file that contains EEG from cmb, and HMP data from t2 appended to t1, combining labels\n",
    "SHORT_DELAY = 300 #ms\n",
    "LONG_DELAY = 1200 #ms\n",
    "SAMPLING_FREQUENCY = 250 #hz\n",
    "\n",
    "# Manual testing showed that actualy delay in EEG data is this value - 6 (69 and 294 respectively), see delay_analysis.ipynb\n",
    "SHORT_PADDING = int((SHORT_DELAY / 1000) * SAMPLING_FREQUENCY) - 6\n",
    "LONG_PADDING = int((LONG_DELAY / 1000) * SAMPLING_FREQUENCY) - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_epochs = t1.trial_index.values\n",
    "t2_epochs = t2.trial_index.values\n",
    "cmb_epochs = cmb.trial_index.values\n",
    "t1_epochs = np.nan_to_num(t1_epochs, nan=-1).astype(int)\n",
    "t2_epochs = np.nan_to_num(t2_epochs, nan=-1).astype(int)\n",
    "cmb_epochs = np.nan_to_num(cmb_epochs, nan=-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = cmb.data.shape\n",
    "new_probas = np.zeros((shp[0], shp[1], t1.probabilities.data.shape[2] + t2.probabilities.data.shape[2] - 1, shp[3] + LONG_PADDING))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(t1_epochs.max() + 1):\n",
    "    # For each possible epoch\n",
    "    # Get indices for each participant where this epoch was valid\n",
    "    t1_idx = np.where(t1_epochs == i)\n",
    "    t1_participants = t1_idx[0].tolist()\n",
    "    t2_idx = np.where(t2_epochs == i)\n",
    "    t2_participants = t2_idx[0].tolist()\n",
    "    cmb_idx = np.where(cmb_epochs == i)\n",
    "    cmb_participants = cmb_idx[0].tolist()\n",
    "    \n",
    "    for p_t1_idx, p_t1 in enumerate(t1_participants):\n",
    "        for p_t2_idx, p_t2 in enumerate(t2_participants):\n",
    "            for p_cmb_idx, p_cmb in enumerate(cmb_participants):\n",
    "                if not (p_t1 == p_t2 == p_cmb):\n",
    "                    continue\n",
    "                # Participant + actual epoch combo occurs in both tasks! Should be combined\n",
    "                t1_epoch = t1_idx[1][p_t1_idx] # p_idx should be the same across all sets\n",
    "                t2_epoch = t2_idx[1][p_t2_idx]\n",
    "                cmb_epoch = cmb_idx[1][p_cmb_idx]\n",
    "                \n",
    "                t1_data = t1.isel(participant=p_t1, epochs=t1_epoch)\n",
    "                t2_data = t2.isel(participant=p_t2, epochs=t2_epoch)\n",
    "                if not t1_data.condition == t2_data.condition:\n",
    "                    print('Conditions not the same, abort')\n",
    "                    break\n",
    "                padding = SHORT_PADDING if t1_data.condition == 'short' else LONG_PADDING\n",
    "                \n",
    "                new_probas[p_t1, cmb_epoch, :t1_data.probabilities.data.shape[0], :500] = t1_data.probabilities.data\n",
    "                new_probas[p_t1, cmb_epoch, t1_data.probabilities.data.shape[0]:, padding:padding+499] = t2_data.probabilities.data[1:]\n",
    "# Cut off at 500 samples / 2 sec since cmb data only goes for 2 s\n",
    "new_probas = new_probas[...,:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmb = cmb.assign(probabilities=(('participant', 'epochs', 'labels', 'samples'), new_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmb.to_netcdf(DATA_PATH / \"prp/stage_data_250hz_combined.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
